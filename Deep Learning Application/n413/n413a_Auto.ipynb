{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ds-cs-N423a.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBQsZEJmubLs"
      },
      "source": [
        "<img src='https://user-images.githubusercontent.com/6457691/90080969-0f758d00-dd47-11ea-8191-fa12fd2054a7.png' width = '200' align = 'right'>\n",
        "\n",
        "## *DATA SCIENCE / SECTION 4 / SPRINT 1 / Assingment 3*\n",
        "\n",
        "---\n",
        "# Neural Network Framework (Keras)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN5Wzlub62DZ"
      },
      "source": [
        "\n",
        "## 기본과제\n",
        "### 케라스 라이브러리를 사용하여 Multi-Layer Perceptron 모델을 CIFAR100 데이터에 적용해보세요.\n",
        "\n",
        "- 시드를 고정하십시오.\n",
        "- 데이터를 Noramlized 해줍니다. \n",
        "- 케라스에서 모델은 다음과 같이 고정합니다. \n",
        "- 활성함수는 ReLU를 사용합니다.\n",
        "- 단계별로 오늘 배운 규제방법을 적용해봅니다. \n",
        "\n",
        "\n",
        "### 문제에 기록된 텍스트를 꼭! 잘 읽어보고 답변을 다셔야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBPLbaggP52G"
      },
      "source": [
        "##### Base #####\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "# 데이터 불러오기\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kAKEMcKdpsC"
      },
      "source": [
        "## 1) X_train, y_train의 Data형태를 출력해서 matrix 구조 [N, x, y, c]를 확인하고 입력해보세요.\n",
        "\n",
        "### 문항 1-1). 데이터의 구조를 출력하기 위한 코드를 입력하세요.\n",
        "\n",
        "### 문항 1-2). Flatten(input_shape=()) 에 들어갈 데이터 형태를 입력하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0r1YrzRNG1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c72f55f8-1b14-4ec4-e4ab-9849d174f36a"
      },
      "source": [
        "##### Your Code Here #####\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(50000, 32, 32, 3), (50000, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7nHEuYmd-p6"
      },
      "source": [
        "Base model을 제작합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_T_3XkVRY2xw"
      },
      "source": [
        "# Step 1. Basic Model\n",
        "\n",
        "# 변수 설정을 따로 하는 방법을 적용하기 위한 코드입니다. \n",
        "batch_size = 100\n",
        "epochs_max = 20\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(##### Your Code Here #####))) ## 문제 1의 데이터구조에서 확인한 내용을 잘 입력하세요\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X_train, y_train, epochs=epochs_max, batch_size=batch_size, verbose=1, validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdxJ5AnieUxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e3d8543-ea61-4e98-f368-765ed3dcf958"
      },
      "source": [
        "model.predict(X_test[0:1])\n",
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 3.3582 - accuracy: 0.2062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbNCUtz4eHIi"
      },
      "source": [
        "## 2) 최종 모델에서 model.evaluate을 통해서 결과를 출력해보세요.  \n",
        "### 문항 2-1). verbose=0 으로 입력해서 출력되는 accuracy를 입력하세요.\n",
        "### 문항 2-2). verbose=1 으로 입력해서 출력되는 accuracy를 입력하세요. <Br>\n",
        "(차이점을 아시겠나요? 차이점을 모른다면 검색해보세요. 정답에 공백을 입력할 수 있어야 합니다.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBQks0_rZWa9"
      },
      "source": [
        "# Step 2. Basic Model + Weight Decay\n",
        "\n",
        "# 변수 설정을 따로 하는 방법을 적용하기 위한 코드입니다. \n",
        "batch_size = 100\n",
        "epochs_max = 20\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(##### Your Code Here #####)))\n",
        "model.add(Dense(128, activation='relu', \n",
        "                kernel_regularizer=regularizers.l2(0.00001),    # L2 norm regularization\n",
        "                activity_regularizer=regularizers.l1(0.00001) )) # L1 norm regularization\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X_train, y_train, epochs=epochs_max, batch_size=batch_size, verbose=1, validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yQeUcY8fp4x"
      },
      "source": [
        "## 3) Dropout을 사용하기 위해서는 라이브러리 추가로 불어와야 합니다. \n",
        "\n",
        "### 문항 3) Dropout의 라이브러리를 호출하기 위해서 사용한 import 문구를 적어주세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_B_mosCZ_Ds"
      },
      "source": [
        "# Step 3. Basic Model + Dropout\n",
        "\n",
        "##### Your Code Here #####\n",
        "\n",
        "\n",
        "# 변수 설정을 따로 하는 방법을 적용하기 위한 코드입니다. \n",
        "batch_size = 100\n",
        "epochs_max = 20\n",
        "\n",
        "# model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(##### Your Code Here #####)))\n",
        "model.add(Dense(128*1.1, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "results = model.fit(X_train, y_train, epochs=epochs_max, batch_size=batch_size, verbose=1, validation_data=(X_test,y_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3RoevKkC27v"
      },
      "source": [
        "### 문항 4) Early Stopping을 사용할 수 있도록 강의자료에서 코드를 잘 발췌해서 사용하시고, 50개의 Epoch를 돌렸을 때 Stop된 epoch 숫자를 입력하세요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjj4th3oLjgu"
      },
      "source": [
        "# Step 4. Basic Model + Early Stopping\n",
        "\n",
        "# 학습시킨 데이터를 저장시키기 위한 코드입니다. \n",
        "checkpoint_filepath = \"FMbest.hdf5\"\n",
        "\n",
        "X_train = X_train / 255.\n",
        "X_test = X_test / 255.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(##### Your Code Here #####)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# 컴파일 단계, 옵티마이저와 손실함수, 측정지표를 연결해서 계산 그래프를 구성함\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# early stopping\n",
        "early_stop = ##### Your Code Here #####\n",
        "\n",
        "# Validation Set을 기준으로 가장 최적의 모델을 찾기\n",
        "save_best = keras.callbacks.ModelCheckpoint(##### Your Code Here #####)\n",
        "\n",
        "results = model.fit(##### Your Code Here #####)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bk3GSXbfUI91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83a26c3-cbfd-46f6-895d-3d9b48140c18"
      },
      "source": [
        "# 학습된 모델을 이용하여 테스트하는 코드\n",
        "\n",
        "model.predict(X_test[0:1])\n",
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 - 1s - loss: 3.4137 - accuracy: 0.1889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyz7CrMIUNJX"
      },
      "source": [
        "model.load_weights(checkpoint_filepath)\n",
        "# best model을 이용한 테스트 데이터 예측 정확도 재확인 코드\n",
        "\n",
        "model.predict(X_test[0:1])\n",
        "test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv_3xNMjzdLI"
      },
      "source": [
        "## 도전과제\n",
        "\n",
        "- 하이퍼 파라미터 튜닝을 사용하여 모델의 정확도를 최대한 높여보세요.\n",
        "- 교차 검증(CV) 기법을 사용하여 모델과 조금 더 일관된 결과를 얻어보세요.\n",
        "- 아직 이론을 배우진 않았지만, Cifar100의 분류문제를 효율적으로 찾기위한 방법을 찾아보세요. \n",
        "- 대부분의 문제풀이는 CNN을 통해서 해결했을 것입니다. \n",
        "- 이제 코드를 보는 방법이 조금씩 익숙해졌기 때문에 다른 사람들이 돌려놓은 파일을 이해해서 돌아가는 샘플코드를 만들어볼 수 있을 것입니다. \n",
        "- 남들이 작성해두었고, 돌아가는 코드를 찾아서 변환하는 것이기 때문에 CNN이라고 해서 어려울 것은 없습니다. \n",
        "- 아직 원리를 모르지만, cifar100 데이터셋을 이용하여 CNN 모델을 구축하고 기본적인 신경망의 결과와 비교해 보십시오. \n",
        "- [참조링크](https://www.kaggle.com/adi160/cifar-10-keras-transfer-learning)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RdyQ2P_lFlX"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 2000\n",
        "num_classes = 100\n",
        "epochs = 20\n",
        "\n",
        "# 데이터 불러오기\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
        "\n",
        "X_train = X_train.astype('float32') / 255.0 - 0.5\n",
        "X_test = X_test.astype('float32') / 255.0 - 0.5\n",
        "\n",
        "X_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=.2)\n",
        "\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkStH7FyFgra",
        "outputId": "b13e081c-fbc7-497f-dfdc-f0ea6b9279b2"
      },
      "source": [
        "[X_train.shape, y_train.shape]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(40000, 32, 32, 3), (40000, 100)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5-JemoY1J2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46dcae58-8b6b-41ea-f806-39e22b4d549f"
      },
      "source": [
        "# transfer\n",
        "from keras.applications import VGG19, ResNet50\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "base_model_1 = VGG19(include_top=False, weights='imagenet', input_shape=(32,32,3), classes=y_train.shape[1])\n",
        "\n",
        "model_1= Sequential()\n",
        "model_1.add(base_model_1) \n",
        "model_1.add(Flatten()) \n",
        "\n",
        "#Add the Dense layers along with activation and batch normalization\n",
        "model_1.add(Dense(1024,activation=('relu'),input_dim=512))\n",
        "model_1.add(Dense(512,activation=('relu'))) \n",
        "model_1.add(Dense(256,activation=('relu'))) \n",
        "# model_1.add(Dropout(.3)) #Adding a dropout layer that will randomly drop 30% of the weights\n",
        "model_1.add(Dense(128,activation=('relu')))\n",
        "# model_1.add(Dropout(.2))\n",
        "model_1.add(Dense(num_classes,activation=('softmax'))) #This is the classification layer\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Functional)           (None, 1, 1, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 21,251,620\n",
            "Trainable params: 21,251,620\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-8tMvFy1kko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bd33f4a-0ace-4862-8a3b-997882a4740c"
      },
      "source": [
        "learn_rate=.001\n",
        "\n",
        "sgd=SGD(lr=learn_rate,momentum=.9,nesterov=False)\n",
        "adam=Adam(lr=learn_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "model_1.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(X_train, y_train, batch_size=batch_size,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=epochs, verbose=1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1250/1250 [==============================] - 47s 24ms/step - loss: 4.0798 - accuracy: 0.0892 - val_loss: 2.7171 - val_accuracy: 0.2910\n",
            "Epoch 2/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 2.5542 - accuracy: 0.3286 - val_loss: 2.2769 - val_accuracy: 0.3923\n",
            "Epoch 3/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 2.0954 - accuracy: 0.4273 - val_loss: 2.0757 - val_accuracy: 0.4449\n",
            "Epoch 4/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.7989 - accuracy: 0.4984 - val_loss: 2.0754 - val_accuracy: 0.4464\n",
            "Epoch 5/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.5617 - accuracy: 0.5541 - val_loss: 1.9458 - val_accuracy: 0.4854\n",
            "Epoch 6/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.3625 - accuracy: 0.6018 - val_loss: 1.8181 - val_accuracy: 0.5159\n",
            "Epoch 7/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.1693 - accuracy: 0.6561 - val_loss: 1.8012 - val_accuracy: 0.5208\n",
            "Epoch 8/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 1.0239 - accuracy: 0.6883 - val_loss: 1.8534 - val_accuracy: 0.5318\n",
            "Epoch 9/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.8553 - accuracy: 0.7336 - val_loss: 1.8625 - val_accuracy: 0.5275\n",
            "Epoch 10/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.7541 - accuracy: 0.7651 - val_loss: 1.8584 - val_accuracy: 0.5412\n",
            "Epoch 11/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.6198 - accuracy: 0.8012 - val_loss: 2.0254 - val_accuracy: 0.5379\n",
            "Epoch 12/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.5205 - accuracy: 0.8321 - val_loss: 2.0520 - val_accuracy: 0.5463\n",
            "Epoch 13/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.4487 - accuracy: 0.8509 - val_loss: 2.2980 - val_accuracy: 0.5343\n",
            "Epoch 14/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.3523 - accuracy: 0.8846 - val_loss: 2.2447 - val_accuracy: 0.5552\n",
            "Epoch 15/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.2954 - accuracy: 0.9043 - val_loss: 2.4751 - val_accuracy: 0.5426\n",
            "Epoch 16/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.2491 - accuracy: 0.9169 - val_loss: 2.3866 - val_accuracy: 0.5503\n",
            "Epoch 17/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.2175 - accuracy: 0.9288 - val_loss: 2.5494 - val_accuracy: 0.5462\n",
            "Epoch 18/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.1982 - accuracy: 0.9347 - val_loss: 2.6222 - val_accuracy: 0.5372\n",
            "Epoch 19/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.1551 - accuracy: 0.9483 - val_loss: 2.7787 - val_accuracy: 0.5497\n",
            "Epoch 20/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.1488 - accuracy: 0.9525 - val_loss: 2.8253 - val_accuracy: 0.5380\n",
            "Epoch 21/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.1194 - accuracy: 0.9623 - val_loss: 2.8298 - val_accuracy: 0.5551\n",
            "Epoch 22/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.1105 - accuracy: 0.9647 - val_loss: 2.9766 - val_accuracy: 0.5531\n",
            "Epoch 23/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.1037 - accuracy: 0.9662 - val_loss: 3.0104 - val_accuracy: 0.5453\n",
            "Epoch 24/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0974 - accuracy: 0.9679 - val_loss: 2.9301 - val_accuracy: 0.5520\n",
            "Epoch 25/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0859 - accuracy: 0.9722 - val_loss: 3.1983 - val_accuracy: 0.5356\n",
            "Epoch 26/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0831 - accuracy: 0.9733 - val_loss: 3.0059 - val_accuracy: 0.5623\n",
            "Epoch 27/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0675 - accuracy: 0.9774 - val_loss: 3.0408 - val_accuracy: 0.5559\n",
            "Epoch 28/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0586 - accuracy: 0.9813 - val_loss: 3.2096 - val_accuracy: 0.5420\n",
            "Epoch 29/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0613 - accuracy: 0.9801 - val_loss: 3.0456 - val_accuracy: 0.5558\n",
            "Epoch 30/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0457 - accuracy: 0.9857 - val_loss: 3.3884 - val_accuracy: 0.5427\n",
            "Epoch 31/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0433 - accuracy: 0.9865 - val_loss: 3.2113 - val_accuracy: 0.5584\n",
            "Epoch 32/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: 3.3614 - val_accuracy: 0.5591\n",
            "Epoch 33/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0487 - accuracy: 0.9840 - val_loss: 3.3222 - val_accuracy: 0.5582\n",
            "Epoch 34/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0375 - accuracy: 0.9880 - val_loss: 3.2700 - val_accuracy: 0.5575\n",
            "Epoch 35/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0385 - accuracy: 0.9875 - val_loss: 3.1482 - val_accuracy: 0.5659\n",
            "Epoch 36/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0359 - accuracy: 0.9885 - val_loss: 3.2897 - val_accuracy: 0.5566\n",
            "Epoch 37/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0392 - accuracy: 0.9882 - val_loss: 3.3348 - val_accuracy: 0.5553\n",
            "Epoch 38/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0203 - accuracy: 0.9939 - val_loss: 3.7065 - val_accuracy: 0.5478\n",
            "Epoch 39/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0406 - accuracy: 0.9873 - val_loss: 3.3603 - val_accuracy: 0.5597\n",
            "Epoch 40/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 3.6228 - val_accuracy: 0.5533\n",
            "Epoch 41/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0281 - accuracy: 0.9914 - val_loss: 3.5188 - val_accuracy: 0.5592\n",
            "Epoch 42/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 3.6608 - val_accuracy: 0.5568\n",
            "Epoch 43/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0201 - accuracy: 0.9937 - val_loss: 3.8507 - val_accuracy: 0.5514\n",
            "Epoch 44/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 3.5868 - val_accuracy: 0.5558\n",
            "Epoch 45/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0427 - accuracy: 0.9871 - val_loss: 3.4668 - val_accuracy: 0.5613\n",
            "Epoch 46/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 3.6233 - val_accuracy: 0.5644\n",
            "Epoch 47/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0264 - accuracy: 0.9911 - val_loss: 3.3348 - val_accuracy: 0.5658\n",
            "Epoch 48/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 3.4363 - val_accuracy: 0.5549\n",
            "Epoch 49/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 3.5446 - val_accuracy: 0.5697\n",
            "Epoch 50/50\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0053 - accuracy: 0.9987 - val_loss: 3.7550 - val_accuracy: 0.5693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbabb79f190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynoPTe_u10Jg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "5042dfe3-d08a-485c-8ae5-f3d0dc4c86ef"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n",
        "\n",
        "#Assign the first subplot to graph training loss and validation loss\n",
        "ax[0].plot(model_1.history.history['loss'],color='b',label='Training Loss')\n",
        "ax[0].plot(model_1.history.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "#Next lets plot the training accuracy and validation accuracy\n",
        "ax[1].plot(model_1.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
        "ax[1].plot(model_1.history.history['val_accuracy'],color='r',label='Validation Accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fba550871d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd3hVVfa/35VCqCIdKSEgIKBIi4iCioqI6Aj2Oj/biHVGxTI641iwfHWsjB0dHduIDhYQsTCgiGIh2EBRegu9txSSrN8f6965NyEJgZSbnLve59nPOfeUe/a+95zP3mfttdcWVcVxHMcJLgmxzoDjOI5TubjQO47jBBwXesdxnIDjQu84jhNwXOgdx3ECjgu94zhOwKkyoReRRBH5XkQmVtU1HcdxnKpt0V8HzK3C6zmO4zhAUlVcRETaACcD9wEjSzu2adOmmpaWVhXZchzHCQyzZs1ar6rNittXJUIPPA7cAjQobqeIjABGAKSmppKRkVFF2XIcxwkGIrK0pH2VbroRkVOAtao6q6RjVHWMqqaranqzZsVWSI7jOM4+UhU2+v7AqSKyBBgLHCcir1XBdR3HcRyqQOhV9TZVbaOqacC5wFRVvbCyr+s4TpzzzjvQqxdMmhTrnMQc96N3HCdYbN8Of/gDnHEGzJ0Lp50GE+Pbq7tKhV5VP1PVU6rymo7jxBEZGdC7N7z4Itx2GyxbBoceCqefDu+/H+vclYwqPPII/O1vlfL13qJ3HKfy2L4dnn3WlpVJfj48+CAccQTs3AlTp8L990Pz5jB5MvTsaS38CRMqNx/7wo4dcN55cNNN8OuvUFBQ4ZdwoXccp/K45hq46iq4/HJrtVYGCxfCCSfArbfCsGHw008wcGBk//77wyefmL3+zDPhvfcqJx/7woIF0K8f/Oc/8MAD8NZbkFDxsuxC7zhO5TB2LLzyigns2LHw9NNlO+/VV+H552Hr1tKPW73aKpIuXeDbb+GFF0wwGzfe/diw2PfuDWedBe++W/ZyqMIHH8BTT1VsZTVpEhx2GKxcCR99BH/+M4hU3PdHo6rVKvXp00cdx6nhLFmi2rCh6hFHqObkqJ58smpysurXX5d+3r33qpqcqtatq3rJJapffqlaUBA5ZvNm1dtvt/2JiapXXqm6cmXZ8rVli+UpKcmutXFj6cf/9pvqkCGRPN1+e9muUxr5+aqjRqmKqPbsqbpoUfm/U1WBDC1BV2Mu7EXTvgp9Zqb9H5Mm7dPpjuNUFLt2qQ4YoNqgQUTENmxQTUtTbdtWdf364s+7+26TpAsvVP3qK9XLL1etX9+2deum+uijqo88otqkiW075xzVefP2Pn9btqj+7nf2HfXqqf7pT7uL7datqrfcYpXTfvvZtS+7zM55/PG9v6aqCfzkyaqDBkXKuWPHvn1XMcSF0Gdnq9aurXrDDft0uuM4FcWoUSYtr75aePvMmaq1almLLD8/sr2gQPWOO+yciy5SzcuL7Nu2TfWFF1T79Yu0qk84QTUjo/z5/OEH1d//3lr3CQmqZ51lbxyvvaZ6wAF2rUsuUV292o7ftUv1tNOKL1tprFun+tBDqh072rlNmqg++WTht5QKIC6EXlV14EBVt/w4TgyZMcPMKeefX/z+Z54x2Rk1yj4XFKj+9a+27dJLC1cARZkzR/Xbbys+z8uXW+u9YcNIZXLYYcWbmbKyVI891so4cWLJ31lQoDp9urXaU1LsOwcMsEokK6viy6BxJPR33GEV8+bN+/wVjlN9yMmp8FZfpbJli2r79maiKekhLCgw8RMxM8att5oMXX556SJfFWzdqvr00ybGpeVlyxZrUdaubWIezcqVqg8+qHrQQVauBg1Ur7lGdfbsys27xpHQT5liJXI7vVPjWb7czAdHHmkdgmVh9mzVp56yB2DBAjM1VCUXXmgt3S+/LP247dtVDz7YzDhgnamxFvm9Ze1a1c6d7S0gI0P13XfN7p+YaGXq399MTtu2VVmWShP6qgpTXCX06wdJSTBtGpx0Uqxz4zj7SG6uuQBu2wa//AI9esB998F110Fi4u7Hr1ljIyr/+c/Cg22Sk+HAA6FTJzjoIHNz7N0bOncuv6/29u2Wt59/hjlz4McfYcoUuOsuOPLI0s+tVw/efhuOOgrOPRdGj648t8LKolkzc9fs3x/S023bAQfAzTfDxRfb712NEKsIqg/p6elannj04XtsxowKypDjVDXXXms+2+PG2Q19xRU2fP/II21of1hEsrPhscdsBGh2tp13zTXmXz5vnqX58yPLnBw7r359Gynauzf06QOnnmp+5nti9WqrcCZOhCVLIttTUqBbNzj2WBudmlTG9mN+fvEVV03i11+tojrlFDjxxLKXvRIQkVmqml7szpKa+rFK5fWjv/VW60SvQK8lx6k6XnvNXv1vvDGyraDAvDwaNTK78MMPq44dq9qunR176ql7Nu/k5qr++KPqSy+p/vGPZhKqW9fOr19fdeRI1WXLij9382brMK1b1x6u009Xvece1XfeMffGaC8ZJ2YQLzZ6VTNPgup//1uur3Ec6wy9/XbVjz8u3/dkZ5uP+MEHm5CX1ME6e7aJ6VFHmTAXZeXKiP83qPboYR1T+0pennmxXHCB2ZaTkszO/uOPtn/nTnMLbNzYrnfuuarz5+/79ZxKJa6EfssW87y5445yfY0T7+TkqA4bFhHVkSNNsPeWL75Q7drVviM11ZbHH797C3zLFtVOnVRbtix9lGdBgepbb6m+8krFtqSXLFG9/nobQAQ2qKdNG1sfMkT1u+8q7lpOpRBXQq9qnk8DB5b7a5x4JTdXdfhwezweecTc40C1V6+ye8Bs3mzeJGAmlkmTTJiffto8NWrVUr3zTvOpLigwc0hiouq0aZVZsj2zYYPqffeZyB9xhOqnn8Y2P06ZiTuhv+EGM2XuSwPMiXNyc010QXX06Mj2994zE0a9eqovvli6f/s776i2amWvliNH7u5it2qVDSgCGy05YoStP/xw5ZTJiQtKE/rAed0AjB8Pw4fD9OkwYEAFZcyp2WRlmafIzp3mrlicd8SuXXD++ebt8thjcP31hfdnZsLvfw+ffgrnnGMeLkuXwqJFlhYvtpC5mZnm1fL88xHXu+L473/h6qvNI+aMMyzyYk1zM3SqDaV53QTKjz5MWNw//9yFPi758ksLK7tkiYnv4sXmax6mSRMYOhR+9ztzidtvP8jLgwsvNJF/9NHdRR6gdWubxOLvfze/9TffLLyvQwcYNAgOP9ymsktOLj2fgwZZ7PT337f8uMg7lUQgW/QA3btDq1bw8ccVkCmnZvDbbxbTe/x4a7GnpkL79pCWFlkmJMCHH1pFsHGjifHAgbb944/h4Yfhxhv3fK25c60i6dAB2rWD2rUrt2yOswfirkUPcMwx8K9/WUMthmMYnKpg7Vq4+2547jmoWxfuvRduuMHWi+O88+zG+Oora01PmGCVxIMPlk3kAbp2teQ4NYDAtujfesvMqN9+a5O4OAFC1Yb679gBTz5pU7Dt3GkjSO+80+YJ3Vs2by7b6FDHqabEZYv+6KNtOW2aC32NYscOi58ye7alOXMspsr27dZZmpdnKZphw6w1Xp74Ii7yToAJrNC3bGmxmz7/3CZXd6oxBQXw0kvw0EMWlyX8llm3Lhx8sHWYNmpkNrikJLOrh9ePOsp73B1nDwRH6PPy4NlnbZb3li0Ba9WPG2c6UgkTqzsVwTffWDCujAwLP3rXXdaT3r27dXT6H+c45SY4T9GSJTByJNxyy/82HX20mV5nz45dtpwSWLMGLrnExH3lSnj9dQs5escdcNpp0LGji7zjVBDBeZI6drRY0K++avYazPMG/vfRqQ5kZdlgpM6dTdz//GcL9Xr++e5H7jiVRLC8bnbuNJe3/faD776D5GTS0mxw4rhxFZpNp6yoWofqJ5+Yn/rnn1tc9JNOgscfN8F3HKfclOZ1E5wWPVjn3ejRJixPPAFYq/7zzyP9e04VMWUKXHSRjVo79FDrEV+50ob8f/qpDVhykXecKiE4nbFhhg2z4eR33gnnnMPRR7fmlVdsPEyXLrHOXByQmWl9JW+9ZaEGTjgBBg+2ZZs2sc6d48QlwWrRg9l5//EP87m+6aZC/vTOPrJ8uXWc3n23+bQXR16emWK6drUQBKNGmei/8Yad6yLvODEjeEIPNiHyrbfC2LF0XDqF1q3hlVcKz5vslJHvvrMgXW+8YUJ/8MFwyCGFRf/rr21U2g032GTJP/9sQb9SUmKbd8dxgKAKPZg3R4cOyB+v5b47c5kxw0bLO3vBBx+Yj2pSkvm5r1hhfR9NmkREv2NHm7R63Trr8Z40ySpax3GqDcEV+jp1zITz66/8vw2PMXSoNfIXLIh1xmoIzzwDp55qYQW+/tpa8a1a2eCmadPMLPPEEyb0N91k0RzPOMNdJB2nGhIs98riGD4cJk9m9adz6TI4lR49zOkjrsfizJhhURsPPhj69DHvl8RE21dQYG9DDz8MJ58MY8dC/fqxza/jOHskLoOa/Y/HH4du3Wg54lReuO1tzrr1QJ56Cv74x1hnLEa8956F9czNjWyrXx969TLRX7zYOlOvvtpcVT3Gs+PUeILfrk1LM9vxsmWccX9v7u39DrfeajO+xR0vvWTmld69LYb77NkWtP/ii81r5rnnLDb7ww9bh4aLvOMEguCbbsIsWQJnnw0zZ/JMresY1/fvTJ5WK35MOI88Yrb0wYPhnXegXr3dj8nLs3DAHrLXcWoc8TMytjTS0uCLL+BPf+Kq3NHc/8VRvHLP0ljnqvJRhb/8xUT+rLOsxV6cyIO14F3kHSdwVPq7uYi0BV4BWgAKjFHV0ZV93WKpVQtGj0YHHEX38y+l0129WJ/9F5q2i+psDHuNNGliXie1asUkqxVCfr7Z2seMgREj4OmnI52ujuPEDVVhhM0DblTV70SkATBLRCaraglDLCsfOetMth7QkzXHnE2PB24u+cDUVPNAufTS6j3588KFFt9n5UpYtcqWK1fa9nnz4Lbb4L773PXRceKUSjfdqOoqVf0utL4NmAu0ruzr7omWAzqy8M0MWskqzjhyFTsXRgnkypU28KdNG7jmGpsA4/HHLTpmdWLbNrj+enOPHD7cWu/33WcDndasse1jxsD997vIO04cU6WdsSKSBnwOHKKqW6O2jwBGAKSmpvZZurTqbOevvw6//73F3Bo/vkjDXdWc7u+5Bz77zCadvvFGuOoqaNCgyvJYLBMmWCWUmWn5ueQSG9DUvLl7yzhOHFJaZyyqWiUJqA/MAk4v7bg+ffpoVfPSS6qgOnSoanZ2CQdNn6564ol2YKNGqnfdpbphQ1Vm01ixQvX00y0f3burzphR9XlwHKfaAWRoCbpaJS16EUkGJgIfq+qjpR1bae6Ve2DMGLjiCoty/J//2PzTxTJzpplHxo+3gUZXX21heVu02LsLrlplLp9ZWYVTdrYNZkpMjEyAHU7LlsG991pkzrvusuuWmFHHceKJ0lr0lS70IiLAy8BGVb1+T8fHSugBnnrKQrmceaYFayzVAjJ7Nvzf/8Gbb5pnzh/+AEcdZe6J0alhQ7OXz5plkSDDafXqfcvk4MEWh6ZDh30733GcQBJroR8ATAdmA+FAwX9R1UnFHR9LoQebznTkSDj3XBs0usdIu/Pnw4MPWhzkXbtKPzYhAbp1s5GpffpAp042K1adOpFUu7ZVHAUFNoApnPLz7fyOHb1j1XGc3Yip0O8tsRZ6gIcegltugSOOsOgJrVqV4aRNm8wcs3mzpU2bIsvGjU3Yu3c3YXccx6lg4juo2T5w883Qvr2FgOnTB95+20Kul0qjRpYcx3GqGfETAmEvOfNMC8Nerx4MHGjxvhzHcWoiLvSlcMgh5mQzaBBceaVFEcjJiXWuHMdx9g4X+j3QqJHN0fGXv8Dzz8Mxx0AVjudyHMcpNy70ZSAx0Vznx42z+bAPPdRG1FazfmzHcZxicaHfC844A3780ZxnLrwQzj/fnGocx3GqMy70e0n79jY3driFf+ihFg7HcRynuuJCvw8kJprN/quvzC3++ONtXg/vqHUcpzriQl8O0tMtmsGVV9pMfYcdZqYdx3Gc6oQLfTmpV88mbvrgA1i3zsT+gQcsYoHjOE51wIW+ghg61CZ5Gj7cJnQ6+mhYsCDWuXIcx3Ghr1CaNLFglq+/bm6YPXrAs8+6G6bjOLHFhb6CETG3y9mzoX9/m/zp+OPts+M4Tixwoa8k2rSBjz6y0PE//gg9e5ror1sX65w5jhNvuNBXIgkJ5pEzf75N7/r88xaC/rHHbBIpx3GcqsCFvgpo3Bj+8Q/46Sfo188mNuneHSYVO/WK4zhOxeJCX4V06wYffggTJ9rnk0+GU06xFr/jOE5l4UJfxYiYwM+ebTNZTZtm4ZBvuw22b4917hzHCSIu9DGiVi0LmzBvns1P+8ADcNBB8O9/uzum4zgViwt9jDngAHj5ZfjyS2jZEi64AI46Cj75xAXfcZyKwYW+mnDkkfDttzBmDCxaBCeeaPPVjh0LeXmxzp3jODUZF/pqRGIiXH45LF4ML7wAO3fCeeeZSefppyErK9Y5dBynJuJCXw1JSYHLLrMwCu+8A82amR9+u3YWB98nO3EcZ29woa/GJCTAaadZ3Ptp0yws8u23Q2oq3HgjrFgR6xw6jlMTcKGvAYhYNMxJkyycwrBhMHo0dOgAl14Kc+fGOoeO41RnXOhrGIceCq+9ZiGQr7jCOmu7dYPBg8010+34juMUxYW+hpKWBk88AUuXwt13mz/+BReYi+YVV5i5x90zHccBF/oaT7NmcMcd5pL56ac28clrr5m7Zpcu8Le/2fbs7Fjn1HGcWCFazZp96enpmpGREets1Gi2bYNx42wg1vTpUFBgnjz9+8Oxx8Jxx9mUh8nJsc6p4zgVhYjMUtX0Yve50AebLVtM7KdOtZb9Dz/Y9oYN4fTTLfzCccdBUlJs8+k4TvlwoXf+x4YN8Nln8P778O67sHWrmX/OOstEv39/c+t0HKdm4ULvFEt2toVNfuMNE/7sbGjVCgYNgoEDLaWlmXun4zjVGxd6Z49s2wYTJlgrf9o0WL/etqemmuAfc4y5cbZvD82bu/g7TnXDhd7ZKwoKLPzCZ59F0oYNkf1161pLv317S507WyXQrZu5d3ol4DhVjwu9Uy4KCuC332yQ1uLFkbRkibl1btsWOXb//U3wu3aFAw+EFi0sNW8eWdauHbOiOE5gKU3o3dfC2SMJCSbcXbvuvk8VVq+2N4C5c235yy9mBlq3rvjva9zYInIedJD5+nfpYusHHugun45TGXiL3qk0du6EtWthzZrCacUKe0P49VerJMKI2BtB48bQqJGl8HqTJiWnhg0txLPjxDPeondiQtiWn5ZW8jFbtkREf+FC6wvYtAk2brTl0qW2vnGjmZCKQ8TEPrpiaNDA3g7CqVYtW6akwH772fHhZcOGdnxKSuFzos9NSbHkFYpTE6kSoReRIcBoIBF4QVUfqIrrOtWfhg2hb19LpVFQYJXChg2FU7gSiK4cNm60N4Vdu3ZP2dmwY8e+5zcx0foYUlKsIqtff/dUu7ZVPsWl8At09FIEmja1aSWLppQUK3vRlJ9vM48VTUUrw3DHeEIC1KtnFVrduqV3mKva7yRi16+szvX8fMuXd95XPpUu9CKSCDwFnACsAGaKyARV/aWyr+0Eh4SEiDmnY8fyfVd+vg0U27rVKo8tW2w9N7f4yiE3F3Jydk87d8L27ZG0cqV1TGdnm1gWl8KCD5FlQYG5s1bVlJEJCYUrprw8i3qalWV5LxoXKfwmFP1mU9x6nTpmegv/T+FUr55VvMuWwfLltly2DFatsnNatrRKrWXLyHpKSuS3j14mJNibWNFUp46Vo+jxubmRcoXLGE45Oba96P+akGCVYd26lvfwenJy5F7IzY2s5+dbBRr9phhO4d8nOkW/YRZN4d+xoqmKFn1fYIGqLgIQkbHAMMCF3okJiYkREaouFBTYG8rq1SaA4RQWt+gkYsvkZAtdkZQUWY8e1Rzd/ZafH6mQtm2zFP6cnGxvIXXqWKpdO+IZFS2A0RVecYK3Zo2Z4TZuhM2bd4+eWru2jctITbU5kVu3tspy9epIh/7UqbvPoJaYGBHH/PzyvZGF8xEuZ7iySkmJfA7/Fzt32rXCy127Clds4WVCgv2OW7faseWhb1/45pvyfUdxVIXQtwaWR31eARwefYCIjABGAKSmplZBlhynepGQYKEomjWD7t1jnZvyU1Bgwrdpk4ngAQdYx3lZzDTZ2Saq4VZv0ZAc4Uor/FYWFtji+mSSkyMVWFjcK9NUlJdnlWg4X9GVYXSlWNyb465d5n5cGVSLzlhVHQOMAfO6iXF2HMcpJwkJZsbZf/+9Pzf6jaI4EhMjnejVjaSk6ve2CFUTjz4TaBv1uU1om+M4jlMFVIXQzwQ6iUh7EakFnAtMqILrOo7jOFTRgCkRGQo8jrlXvqiq95Vy7DpgaTku1xRYX47zaype7vjCyx1flKXc7VS1WXE7qt3I2PIiIhkljQ4LMl7u+MLLHV+Ut9w+xYTjOE7AcaF3HMcJOEEU+jGxzkCM8HLHF17u+KJc5Q6cjd5xHMcpTBBb9I7jOE4ULvSO4zgBJzBCLyJDROQ3EVkgIrfGOj+ViYi8KCJrRWRO1LbGIjJZROaHltVsEHb5EJG2IvKpiPwiIj+LyHWh7UEvd20R+VZEfgyV++7Q9vYi8k3ofn8zNBgxcIhIooh8LyITQ5/jpdxLRGS2iPwgIhmhbft8rwdC6KNCIZ8EdAPOE5Fusc1VpfIvYEiRbbcCU1S1EzAl9DlI5AE3qmo3oB9wTeg/Dnq5c4DjVLUH0BMYIiL9gAeBx1S1I7AJuCyGeaxMrgPmRn2Ol3IDHKuqPaP85/f5Xg+E0BMVCllVc4FwKORAoqqfAxuLbB4GvBxafxkYXqWZqmRUdZWqfhda34Y9/K0JfrlVVbeHPiaHkgLHAeNC2wNXbgARaQOcDLwQ+izEQblLYZ/v9aAIfXGhkFvHKC+xooWqrgqtrwZaxDIzlYmIpAG9gG+Ig3KHzBc/AGuBycBCYLOqhqcqCer9/jhwCxCeN6sJ8VFusMr8ExGZFQrjDuW416tFmGKnYlFVFZFA+s2KSH3gbeB6Vd0qUcHFg1puVc0HeorI/sC7QJcYZ6nSEZFTgLWqOktEBsY6PzFggKpmikhzYLKI/Bq9c2/v9aC06D0UMqwRkQMAQsu1Mc5PhSMiyZjIv66q74Q2B77cYVR1M/ApcASwv4iEG2pBvN/7A6eKyBLMFHscNu900MsNgKpmhpZrscq9L+W414Mi9B4K2cp7UWj9ImB8DPNS4YTss/8E5qrqo1G7gl7uZqGWPCJSB5t7eS4m+GeGDgtcuVX1NlVto6pp2PM8VVUvIODlBhCReiLSILwODAbmUI57PTAjY/cmFHJNR0TeAAZioUvXAHcC7wFvAalYmOezVbVoh22NRUQGANOB2URstn/B7PRBLvehWMdbItYwe0tVR4lIB6yl2xj4HrhQVXNil9PKI2S6uUlVT4mHcofK+G7oYxLwb1W9T0SasI/3emCE3nEcxymeoJhuHMdxnBJwoXccxwk4LvSO4zgBp9r50Tdt2lTT0tJinQ3HcZwaxaxZs9aXNGfsHoVeRF4EwoMXDilmv2D+rUOBncDF4aHqInIRcHvo0HtV9eWi5xclLS2NjIyMPR3mOI7jRCEiS0vaVxbTzb/YPYBWNCcBnUJpBPBM6KKNMbe/wzFn/zuDFlnQcRynJrDHFr2qfh6KLVISw4BX1Pw0vxaR/UOjtgYCk8N+niIyGasw3ihvph3HcaJRhahoGNWKggLIyYHsbEs5OYVTbm5kWb8+DBhQ8XmoCBt9SQHFyhxoLBS0ZwRAampqBWTJcZzSUIXt22HTJqhVC+rVs5RQwjt+Xh7s2GHnZGXtLlI5ObYvM7NwWrkSNm6EAw+E7t3h0ENt2b07NG5s+Vi1CubPhwULIikrC1JSoHbtyLJ2bcvHhg2wfr2l8PqOHZCcDHXqFE5161q56tffPYX3Fz1H1b5v587Cy1277LcqmgDWrYO1a2HNmkhat87O3bWr7P/L4YfD11+X//8tSrXojFXVMYQmv01PT/cRXE7gKCiA/HxbFzFBFbGUlwdLl5rYRacFC6wFmJRUOCUmmqilpOyekpNNqAoKbBlOeXkmuGFh3LDBRLoodeqYCNarZ/kNi3txx5ZEUhK0agWtW5ug77+/leftt+H55yPHtWwJW7eaGIZJTob27aFBg91bwdnZ9ns1bWqpZUs45BBo0gT228+Oycqy78vKiqQdO0x4Fy60soRT+P8oCwkJlrfcXPs9i6NJE2jRwlJ6OjRrZr9ldEUV/p9q17ZKIiUlskxJgYYNy56nvaEihL6kgGKZmPkmevtnFXA9x6lwcnJMEMJCEZ2iRSP689at1iLetMlENLy+bZsJ665dkWVBwZ7zEKZBA+jUCXr3NqHIyyucwt8bbklv3RpZ37Vr94pExCqHxo2tZd23r4lS06bQqJF91/btEVEPLxMTI63hcIu/Xj1rBRcVqJQU296qlQlccW8G4db7Tz/B7Nkwd65VAp06QceOllJT7bqVjar9VtH/bTglJETeBMLLWrUipqH8fBP8cCoosN8zqVo0m4unIrI2AbhWRMZiHa9bVHWViHwM3B/VATsYuK0Cruc4u7FrF6xebUKyciVs2WIClp9feJmVZa271asjy9Wr7fi9pVYtE8pwatkSunY1oU5OjqSkJFuGBSzcyg63ukVM4Dp1stSiRfW1N5cHEasIWrWCIaW5d1RRXsKml71tRScmRsw8NYWyuFf+L4CWiKzAPGmSAVT1WWAS5lq5AHOvvCS0b6OI3INFlgQYFaRgU07VkZdn9t5lyywtXRpZz8w0cV+3ruzft99+JsotW5rNePBgaN7cWq516xZO0Xbcovbc6Fae41Rnql1Qs/T0dHU/+vgjK8te6RcuhEWLYPFiS4sWwYoVu9tTmzaFtm2hTRtrIR5wQCS1amUt7KJ27aSkiH3UcYKGiMyKml+2ENXYquQEFVVYvopn39sAABYWSURBVBy++gpmzLDl999byz1My5bWKTdggC3btTPzRrt2JvB168Yu/45T03ChdyqFrCzztFi+3Frky5dH1n/7zUwuYIJ92GFw883mWta5M6Sl1Sz7p+NUd1zonQqhoAB++AEmT7b0xRfmBRImIcFMKm3bwsCB0K8fHHGE2ciTk2OWbceJC1zonX1iyxaYM8fs6p99BlOmmG82mO/0NddYCz011ezoLVtWb/czxwky/ug5e2TnTvjgA/juO/N/nj3bPF7CHHAAnHwynHACDBpkou44TvXBhd4pFlUbiv3SSzB2rA0CSkqCLl2gf3+48srIUPbUVHczdJzqjAu9U4hVq+DVV03gf/3VOkvPPhsuvths6uHYHo7j1Bxc6B3AvGDuussEPj/f3Br/+U846ywb6ek4Ts3FhT7O2bQJHnwQRo82gb/mGkudO8c6Z47jVBQu9HFKdjY8+STcfz9s3gwXXACjRtngJMdxgoULfRyhanb3996DZ56xAUwnnQT/93/Qo0esc+c4TmXhQh9w8vPhm29M3MePh3nzbPuAAfDyy3DssbHNn+M4lY8LfUBZvx4eeMA8aNautdGnxx4L118Pp55qk0I4jhMfuNAHjB074PHH4e9/t8kjTj8dzjjDTDSVNXuN4zjVGxf6gJCXBy++aC6Sq1bBsGHW0dqtW6xz5jhOrClhKmCnpqAK775rc2decYV5zUyfbjZ5F3nHccCFvkbz/fdmdz/9dAtB8N57FjVywIBY58xxnOqEC30NZNUquOwy6NMHfv4Znn7aAo0NG+YxZxzH2Z0yCb2IDBGR30RkgYjcWsz+x0Tkh1CaJyKbo/blR+2bUJGZjzeysszu3rmzedOMHGmTe1x1lYcAdhynZMoyOXgi8BRwArACmCkiE1T1l/AxqnpD1PF/BHpFfUWWqvasuCzHJx9+aIK+dCkMHw4PPQQdO8Y6V47j1ATK0qLvCyxQ1UWqmguMBYaVcvx5wBsVkTnH/OF//3sYOhTq1YOpU63z1UXecZyyUhahbw0sj/q8IrRtN0SkHdAemBq1ubaIZIjI1yIyvITzRoSOyVi3bl0Zsx5sVOHNN81zZuxYuOMOm/jDR7I6jrO3VLRl91xgnKrmR21rp6qZItIBmCois1V1YfRJqjoGGAOQnp6uFZynGkdmJlx9NUyYYBNnT5liE3w4juPsC2Vp0WcCbaM+twltK45zKWK2UdXM0HIR8BmF7fdOFKoWf6ZbN5tg+5FH4KuvXOQdxykfZRH6mUAnEWkvIrUwMd/Ne0ZEugCNgK+itjUSkZTQelOgP/BL0XMdm1g7PJNTz57mLjlyJCQmxjpnjuPUdPZoulHVPBG5FvgYSAReVNWfRWQUkKGqYdE/FxirqtGml67AcyJSgFUqD0R76zjG5Mkm8OvW2SQgN97oAu84TsUhhXU59qSnp2tGRkass1ElZGfDbbdZELIuXeD116F371jnynGcmoiIzFLV9OL2+TCbGPHjj3DhhTBnDlx7rbXk69aNda4cxwkiHgKhisnJgb/9DdLTzVQzaRI88YSLvOM4lYe36KuQr76yGDVz58L/+3/w6KPQpEmsc+U4TtDxFn0VsGOHzezUv79NBjJpkrlRusg7jlMVeIu+kvnsM7j0Uli8GK65xibibtAg1rlyHCee8BZ9JfLkk3D88RZZ8vPP7bOLvOM4VY236CuBvDwz1Tz1FPzud/Dvf0P9+rHOleM48Yq36CuYLVvglFNM5G+80SJNusg7jhNLvEVfgSxaZC34efPg+efhD3+IdY4cx3Fc6CuML76A006D/Hz45BMPJ+w4TvXBTTflRBWeew6OOw4aNYJvvnGRdxyneuFCXw6ysmwA1JVXmnfN119Dp06xzpXjOE5h3HSzjyxdCqefbrM+/e1vcOedHnHScZwysGIFbN4MCQkgYstwqlMHWrWq8Eu60O8DkyfDeeeZG+WECdYB68QRqhbPYtUqaNsW2rSBFi1iV9OrWudQfmhit6SkiIiUhbw8WLIE5s83T4L582HBAnMX69o1kg46qGKDMm3dCrVrQ61aZTu+oABycyElpexlKys7d8Lq1ZY2bIBt2yx/0WnHDrt+bq4FrQqvJyTYbEE9e0KvXvZbRZdp1Sr49FNLU6ea10ZJHH64mQYqGBf6vUDVokz+9a/2v77zToBMNdnZMHGi9SoffDD062eF3JN4bd9uD13duuV/+FTL9h35+fDttxZLYsMGawVFp9q1Lb5Ehw5w4IHWeVLS9+7YAcuX2yzsPXqUPqItPx/Gj7eb4NtvC+9LSrKWWJs2NnP7UUfB0UfbDVLctfPy4IcfYPp0+P57O+fII+1BLy4P27bZMOtPPrGWxtKl9h35+fa7FUdSUiQlJhZO4W1gc1fm5UXO228/y/fixfDee5EKRATS0qyMtWrtnurVs/3t21vq0AGaNrXztm2DWbNg5kzIyLDl4sX2vS1aRCrM8DI/H1autJSZactVqyyfCQl2v9WrF0kNGtj3tGxpKbzetKlde/16u1eil2vWmLCvWmXHlERCAjRsaNdMSbEUXe7cXHOz27nTjq9Vy56hzp3hp58suBXYdwwcCH/6k90rqlZ5hZNqpcVF8Xj0ZSQnx+zxr78O554LL7xg91eVsmEDJCdbSyuhmO6V3FxrLcyfH0kpKRYq87DD7OGNPq+gwIT91VfhP/+xQQDJybBrl+2vXx/69jXR793bWjULF9o1wik8mXtKCjRuXDi1amWB9sOpTZvI9fPz4eefrfXyzTe2nDfPWo3p6ZHUo4eJ95YtJnITJ5rAr19vQtWokXWWZGVZeYqjYUMT/AMPtAd/5UpYtszShg2R45KTTaCHDIGTTrKHVcT+/FdegYcftjx26AA33WS/S2amvYovX27LFSss9vTatfadLVpERL9zZxO46dNhxgyrJMPHrF1rD3pCgs0d2b+/if6yZVbur74ykatbF445xvIWFutoIQ//tnl5u6dwqz86FRTY/9Kpk+WvUydo1ixSOeXkWOv+l19MsObONWHctcvut/AyN9fuj/D9EKZePfu+pUsjFVJamt2PvXrZ+dG/3fLl9l8D7L+/3UOtW9uyVSu7J7OyrIIOp5077Zw1ayytX1/yMyRi92aTJpFKoWVLOOCAyHqTJnbP7LefpTp19twAyc+35+2HHyx9/z38+qs1lo491rw1evWq1Le+0uLRu9CXgfXrzXXyiy/gvvtsspByvznu2mUPesOGxYu2qj1U06db+uILe1jALt6gQeRmbNDAbvClSwuLXaNG9qCGWxoNG0KfPvaQicAbb9g59erBGWdYgPxjj7XX+K+/jqQff4y0+BITITXVRLNDB2u5JSTAxo0mmhs3RtaXLYs8tGAiddBB9rB+9509pGAPXr9+Vhn89pu1+NasiVyvY0erYPLy7NiTTrJRaSeeaGUM/167dkVEf906q4jCFdPChZY2bDDhaNvWypGaausNG9rv/NFHNo8j2Pajj7bZ2Vevtsruz3+236q0B1bVKoTPP7c0fXrkvwM45BD73qOOstS6tf1O33xjFcCXX9rvHn5b6t0bBg+GE06wVn9KSplusZiwfbvdP4sXW1q0yP7Lrl3tvktPN+EvjW3b7PfdVzPRrl1Wca5ebQ/vfvuZeDdtapVHcc9bAHChLwfz5sHQodbYePllOOecffiSHTvsFe777y398IOJSU6O3XSNGtmNGE5gLbhwa7N5cxOEww+347dssbR1a2TZrJm1xqJTkyYmjnPnmqlh5kxLP/1kFcLgwSbuw4eX/nqSlWWt78aNTfySk8tWblV74H79tXDassUqnH79rEwHHli45lS1lnJGhr3u//STCcUpp9g5SZVscVyxwgT/o4/MXBIW+OOO2/cafulSaxn36mW/457Iz7ffqnnzPQuj41ABQi8iQ4DR2JyxL6jqA0X2Xww8BGSGNj2pqi+E9l0E3B7afq+qvlzataqT0E+bZi35pCQzzR5xRAkH5ufDBx/Yq9vatZbWrbPlmjX2Ohr+nRs3toe9Z09ryYVbv+G0fr21SPr2jbT4Onas2M6n7GwT73Br2HGcGk+5phIUkUTgKeAEYAUwU0QmFDPJ95uqem2RcxsDdwLpgAKzQudu2odyVCmvvGIhDDp2NA1v376Yg1Th/fetd3bOHNtWq5a1wsKpSxczcfTqZalt24r3GNhbate25DhOXFCWd+C+wAJVXQQgImOBYUBRoS+OE4HJqroxdO5kYAjwxr5lt2p49FELSHb88TBunJn1dmPaNDPWf/WVmUnGjjXbcYMGsRdyx3GcKMrSK9EaWB71eUVoW1HOEJGfRGSciLTdm3NFZISIZIhIxrqivfZVzCuvmMifeSZ8+GExIv/dd+aVMXCg2V3HjDH79TnnWKePi7zjONWMiup+fh9IU9VDgclAqXb4oqjqGFVNV9X0ZjHsePrgA5sNatAgeO21In2OO3fCdddZJ+LMmfDQQ9a5dvnlZe+cdBzHiQFlEfpMoG3U5zZEOl0BUNUNqpoT+vgC0Kes51YXvvwSzjrLzOjvvFPEg23GDOs8/cc/4NprzWXsppvMv9ZxHKeaUxahnwl0EpH2IlILOBeYEH2AiBwQ9fFUIDQUjI+BwSLSSEQaAYND26oVc+aY517btjYW538DE7Oz4ZZbzPMlN9eGLz/xhPlcO47j1BD22Bmrqnkici0m0InAi6r6s4iMAjJUdQLwJxE5FcgDNgIXh87dKCL3YJUFwKhwx2x1YckSG3dTty58/HGUy3JGBlx0kY0IHDHCRkX6hK+O49RA4nfAlCrbHnyaX0aNg9xcDj0ohzoJOZGARStW2HDof/7TagLHcZxqTLn86ANJQQF68y00ePQR6kp32vZpQZ3m+0cCFqWk2GCmm28uwbfScRyn5hB/Qr9rF1x2GfLqqzzBtdR5djTdRwQz9oXjOA7Em9Dv2AFnnw2TJjEq+R6+HPhXPrrc/d4dxwk28SP0GzfCySej337Lo52f4+FVI5jzgo9vchwn+MSHzWLFCnOR/P57Pr7sP9w0bwSPPGIRah3HcYJO8Fv0OTk21HXVKlb/6yPO/MNABg2ygGWO4zjxQPCF/okn4Lff0A8mccEjAxGx2aHcZOM4TrwQbKFftw7uuQeGDmXM8pOYOhWefRbatYt1xhzHcaqOYAv9HXfAjh1kjnyEm4bbBEEjRsQ6U47jOFVLcDtjZ8+2EMLXXMMVj3VB1Qa5usnGcZx4I5gtelUYORIaNmTd1XcyqSvcfrtNPu84jhNvBFPoP/gA/vtfGD2aiTMaowqnnx7rTDmO48SG4JlucnNtiqiDDoKrrmL8eAs/3KNHrDPmOI4TG4LXon/6aZg3DyZOJCsvmU8+sVmj3DbvOE68EqwW/YYNcPfdMHgwDB3KlCmQlQWnnhrrjDmO48SOYAn9XXfB1q3w6KMgwoQJNlfIMcfEOmOO4zixIzhCP38+PPMMXHklHHwwBQXw/vswZEiR+V8dx3HijODY6A88EP71L1N2bCbA1avdbOM4jlOmFr2IDBGR30RkgYjcWsz+kSLyi4j8JCJTRKRd1L58EfkhlCYUPbfCSEiACy+Epk0BmDABEhNh6NBKu6LjOE6NYI8tehFJBJ4CTgBWADNFZIKq/hJ12PdAuqruFJGrgL8D54T2ZalqzwrO9x6ZMMEiEzduXNVXdhzHqV6UpUXfF1igqotUNRcYCwyLPkBVP1XVnaGPXwNtKjabe8fixRYBwc02juM4ZRP61sDyqM8rQttK4jLgw6jPtUUkQ0S+FpHhxZ0gIiNCx2SsW7euDFkqnQkhA5ELveM4TgV3xorIhUA6EO3Q2E5VM0WkAzBVRGar6sLo81R1DDAGID09XcubjwkToFs36591HMeJd8rSos8E2kZ9bhPaVggRGQT8FThVVXPC21U1M7RcBHwG9CpHfvfIpk0wbZq35h3HccKURehnAp1EpL2I1ALOBQp5z4hIL+A5TOTXRm1vJCIpofWmQH8guhO3wvnoI8jPd6F3HMcJs0fTjarmici1wMdAIvCiqv4sIqOADFWdADwE1Af+IxZUZpmqngp0BZ4TkQKsUnmgiLdOhTNhAjRvDn37VuZVHMdxag5lstGr6iRgUpFtd0StDyrhvBlA9/JkcG/IzYUPP4QzzjAfesdxHCdIIRCA6dNhyxY32ziO40QTKKEfPx5q14ZBxb5fOI7jxCeBEXpVs88PGgT16sU6N47jONWHwAj94sWQmQnDhu35WMdxnHgiMNErO3SAdesgKTAlchzHqRgCJYv77x/rHDiO41Q/AmO6cRzHcYrHhd5xHCfgiGq5Y4hVKCKyDlhajq9oCqyvoOzUJLzc8YWXO74oS7nbqWqz4nZUO6EvLyKSoarpsc5HVePlji+83PFFecvtphvHcZyA40LvOI4TcIIo9GNinYEY4eWOL7zc8UW5yh04G73jOI5TmCC26B3HcZwoXOgdx3ECTmCEXkSGiMhvIrJARG6NdX4qExF5UUTWisicqG2NRWSyiMwPLRvFMo8VjYi0FZFPReQXEflZRK4LbQ96uWuLyLci8mOo3HeHtrcXkW9C9/uboWk+A4eIJIrI9yIyMfQ5Xsq9RERmi8gPIpIR2rbP93oghF5EEoGngJOAbsB5ItIttrmqVP4FDCmy7VZgiqp2AqaEPgeJPOBGVe0G9AOuCf3HQS93DnCcqvYAegJDRKQf8CDwmKp2BDYBl8Uwj5XJdcDcqM/xUm6AY1W1Z5T//D7f64EQeqAvsEBVF6lqLjAWCGzAYlX9HNhYZPMw4OXQ+svA8CrNVCWjqqtU9bvQ+jbs4W9N8Mutqro99DE5lBQ4DhgX2h64cgOISBvgZOCF0GchDspdCvt8rwdF6FsDy6M+rwhtiydaqOqq0PpqoEUsM1OZiEga0Av4hjgod8h88QOwFpgMLAQ2q2pe6JCg3u+PA7cABaHPTYiPcoNV5p+IyCwRGRHats/3eqDCFDuGqqqIBNJvVkTqA28D16vqVmvkGUEtt6rmAz1FZH/gXaBLjLNU6YjIKcBaVZ0lIgNjnZ8YMEBVM0WkOTBZRH6N3rm393pQWvSZQNuoz21C2+KJNSJyAEBouTbG+alwRCQZE/nXVfWd0ObAlzuMqm4GPgWOAPYXkXBDLYj3e3/gVBFZgplijwNGE/xyA6CqmaHlWqxy70s57vWgCP1MoFOoR74WcC4wIcZ5qmomABeF1i8CxscwLxVOyD77T2Cuqj4atSvo5W4WaskjInWAE7D+iU+BM0OHBa7cqnqbqrZR1TTseZ6qqhcQ8HIDiEg9EWkQXgcGA3Mox70emJGxIjIUs+klAi+q6n0xzlKlISJvAAOx0KVrgDuB94C3gFQszPPZqlq0w7bGIiIDgOnAbCI2279gdvogl/tQrOMtEWuYvaWqo0SkA9bSbQx8D1yoqjmxy2nlETLd3KSqp8RDuUNlfDf0MQn4t6reJyJN2Md7PTBC7ziO4xRPUEw3juM4Tgm40DuO4wQcF3rHcZyA40LvOI4TcFzoHcdxAo4LveM4TsBxoXccxwk4/x9n3+o13BoXPgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdl_5S9xQ4Na",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5e2338-d711-4dc9-ae72-4ead68060cf8"
      },
      "source": [
        "model_1.predict(X_test)\n",
        "test_loss, test_acc = model_1.evaluate(X_test, y_test, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 3.7550 - accuracy: 0.5693\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}